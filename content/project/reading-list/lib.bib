
@incollection{conner_getting_2012,
	address = {New York,  NY,  US},
	title = {Getting started: {Launching} a study in daily life.},
	isbn = {978-1-60918-747-7 (Hardcover); 978-1-60918-749-1 (PDF)},
	abstract = {Capturing naturalistic human experience is a fundamental challenge for researchers in psychology and related fields. Fortunately, as demonstrated by the broad scope of this handbook, there is an increasing number of methodologies for studying the full range of experiences, behavior, and physiology as people go about their daily lives. Our goal in this chapter is to provide a starting point for researchers interesting in using these methods. Our aim is to provide practical guidance and basic considerations in how to design and conduct a study of individuals over time in their naturalistic environments. We explain how basic design considerations depend on a number of factors—the type of research question, the characteristics of the sample of interest, the nature of the phenomena under investigation, and the resources available to conduct the research. We address each consideration in turn and integrate our practical discussions with examples that draw on different types of research questions. In this way, our chapter lays a foundation for the more advanced chapters that follow in this section of the Handbook. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
	booktitle = {Handbook of research methods for studying daily life.},
	publisher = {The Guilford Press},
	author = {Conner, Tamlin S. and Lehman, Barbara J.},
	year = {2012},
	keywords = {Behavior, Physiology, Research Psychologists, *Environment, *Experiences (Events), *Experimental Design, *Experimentation, *Methodology},
	pages = {89--107},
	file = {Getting Started\: Launching a Study in Daily Life:/Users/I567291/Zotero/storage/DPP2R5EH/otago057491.pdf:application/pdf},
}

@inproceedings{rieman_diary_1993,
	address = {New York, NY, USA},
	series = {{CHI} '93},
	title = {The diary study: a workplace-oriented research tool to guide laboratory efforts},
	isbn = {978-0-89791-575-5},
	shorttitle = {The diary study},
	url = {https://dl.acm.org/doi/10.1145/169059.169255},
	doi = {10.1145/169059.169255},
	abstract = {Methods for studying user behavior in HCI can be informally divided into two approaches: experimental psychology in the laboratory and observations in the workplace. The first approach has been faulted for providing results that have little effect on system usability, while the second can often be accused of yielding primarily anecdotal data that do not support general conclusions. This paper describes two similar approaches in another field, the study of animal behavior, and shows how they produce complementary results. To support similar complementary interactions between research approaches in the HCI field, the paper describes the diary study technique, a tool for research in the workplace that achieves a relatively high standard of objectivity. A diary study is reported that focuses on exploratory learning.},
	urldate = {2023-06-12},
	booktitle = {Proceedings of the {INTERACT} '93 and {CHI} '93 {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Rieman, John},
	month = may,
	year = {1993},
	keywords = {diary studies, exploratory learning, methodologies, participatory design, situated cognition},
	pages = {321--326},
	file = {Full Text PDF:/Users/I567291/Zotero/storage/NEBLAZ2V/Rieman - 1993 - The diary study a workplace-oriented research too.pdf:application/pdf},
}

@article{barke_grounded_2023,
	title = {Grounded {Copilot}: {How} {Programmers} {Interact} with {Code}-{Generating} {Models}},
	volume = {7},
	shorttitle = {Grounded {Copilot}},
	url = {https://dl.acm.org/doi/10.1145/3586030},
	doi = {10.1145/3586030},
	abstract = {Powered by recent advances in code-generating models, AI assistants like Github Copilot promise to change the face of programming forever. But what is this new face of programming? We present the first grounded theory analysis of how programmers interact with Copilot, based on observing 20 participants—with a range of prior experience using the assistant—as they solve diverse programming tasks across four languages. Our main finding is that interactions with programming assistants are bimodal: in acceleration mode, the programmer knows what to do next and uses Copilot to get there faster; in exploration mode, the programmer is unsure how to proceed and uses Copilot to explore their options. Based on our theory, we provide recommendations for improving the usability of future AI programming assistants.},
	number = {OOPSLA1},
	urldate = {2023-06-12},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Barke, Shraddha and James, Michael B. and Polikarpova, Nadia},
	month = apr,
	year = {2023},
	keywords = {AI Assistants, Grounded Theory, Program Synthesis},
	pages = {78:85--78:111},
	file = {Full Text PDF:/Users/I567291/Zotero/storage/ZKMQXQBD/Barke et al. - 2023 - Grounded Copilot How Programmers Interact with Co.pdf:application/pdf},
}

@inproceedings{vaithilingam_expectation_2022,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '22},
	title = {Expectation vs. {Experience}: {Evaluating} the {Usability} of {Code} {Generation} {Tools} {Powered} by {Large} {Language} {Models}},
	isbn = {978-1-4503-9156-6},
	shorttitle = {Expectation vs. {Experience}},
	url = {https://dl.acm.org/doi/10.1145/3491101.3519665},
	doi = {10.1145/3491101.3519665},
	abstract = {Recent advances in Large Language Models (LLM) have made automatic code generation possible for real-world programming tasks in general-purpose programming languages such as Python. However, there are few human studies on the usability of these tools and how they fit the programming workflow. In this work, we conducted a within-subjects user study with 24 participants to understand how programmers use and perceive Copilot, a LLM-based code generation tool. We found that, while Copilot did not necessarily improve the task completion time or success rate, most participants preferred to use Copilot in daily programming tasks, since Copilot often provided a useful starting point and saved the effort of searching online. However, participants did face difficulties in understanding, editing, and debugging code snippets generated by Copilot, which significantly hindered their task-solving effectiveness. Finally, we highlighted several promising directions for improving the design of Copilot based on our observations and participants’ feedback.},
	urldate = {2023-06-12},
	booktitle = {Extended {Abstracts} of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Vaithilingam, Priyan and Zhang, Tianyi and Glassman, Elena L.},
	month = apr,
	year = {2022},
	keywords = {github copilot, large language model},
	pages = {1--7},
	file = {Full Text PDF:/Users/I567291/Zotero/storage/K7W9QFHM/Vaithilingam et al. - 2022 - Expectation vs. Experience Evaluating the Usabili.pdf:application/pdf},
}

@article{alabood_systematic_2023,
	title = {A systematic literature review of the {Design} {Critique} method},
	volume = {153},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584922001902},
	doi = {https://doi.org/10.1016/j.infsof.2022.107081},
	abstract = {Context: The Design Critique (DC) method is becoming more common in Human–Computer Interaction (HCI) and User Experience (UX) studies as the need for new evaluation methods of emerging technologies is increasing. However, there is an clear lack of guidelines on how to conduct DC studies in the UX context. Objective: The goal of this paper is to provide an overview of the DC method in the fields of UX. In addition, this paper aims to propose a generic process of running DC studies in the same context. Methods: We present a systematic literature review of the DC method. Moreover, we conduct a course of thematic analysis on the selected papers to identify the various DC processes and explore the following attributes: participant categories, data collection methods, and data analysis methods in each process. Results: We identified three different trends of DC processes: detailed, moderate and minimal. In addition, we proposed a generic DC process consisting of 10 steps divided into three main phases: preparation, conducting design critique, and pro-processing. We found that domain experts represent the majority of studies participants. Using interviews to collect qualitative data and using script coding analysis are the two most common methods of collecting and analyzing data. Conclusion: Conducting DC studies can improve overall systems usability by addressing design flaws at an early stage of development. The process of conducting a DC varies, depending on the project goals and states. The DC method aligns well with the small light-weight steps approach in Agile methods.},
	journal = {Information and Software Technology},
	author = {Alabood, Lorans and Aminolroaya, Zahra and Yim, Dianna and Addam, Omar and Maurer, Frank},
	year = {2023},
	keywords = {AgileUX, Design Critique, Human-centered design, Systematic literature review, User-experience research},
	pages = {107081},
}
